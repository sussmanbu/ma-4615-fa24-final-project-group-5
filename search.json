[
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "#Write data description Blog Post 1: dataset description Blog Post 2: dataset origin, problems with data, importance of data Blog Post 3: Data Equity paragraphs, changed “*” to NA and assumed 0, and summed up various columns to see the proportionality of race, gender, and job types with aggregation, and lastly, create link for cleaned dataset file\nThis comes from the file data.qmd.\nYour first steps in this project will be to find data to work on.\nI recommend trying to find data that interests you and that you are knowledgeable about. A bad example would be if you have no interest in video games but your data set is about video games. I also recommend finding data that is related to current events, social justice, and other areas that have an impact.\nInitially, you will study one dataset but later you will need to combine that data with another dataset. For this reason, I recommend finding data that has some date and/or location components. These types of data are conducive to interesting visualizations and analysis and you can also combine this data with other data that also has a date or location variable. Data from the census, weather data, economic data, are all relatively easy to combine with other data with time/location components."
  },
  {
    "objectID": "data.html#what-makes-a-good-data-set",
    "href": "data.html#what-makes-a-good-data-set",
    "title": "Data",
    "section": "What makes a good data set?",
    "text": "What makes a good data set?\n\nData you are interested in and care about.\nData where there are a lot of potential questions that you can explore.\nA data set that isn’t completely cleaned already.\nMultiple sources for data that you can combine.\nSome type of time and/or location component."
  },
  {
    "objectID": "data.html#where-to-keep-data",
    "href": "data.html#where-to-keep-data",
    "title": "Data",
    "section": "Where to keep data?",
    "text": "Where to keep data?\nBelow 50mb: In dataset folder\nAbove 50mb: In dataset_ignore folder. This folder will be ignored by git so you’ll have to manually sync these files across your team.\n\nSharing your data\nFor small datasets (&lt;50mb), you can use the dataset folder that is tracked by github. Add the files just like you would any other file.\nIf you create a folder named data this will cause problems.\nFor larger datasets, you’ll need to create a new folder in the project root directory named dataset-ignore. This will be ignored by git (based off the .gitignore file in the project root directory) which will help you avoid issues with Github’s size limits. Your team will have to manually make sure the data files in dataset-ignore are synced across team members.\nYour load_and_clean_data.R file is how you will load and clean your data. Here is a an example of a very simple one. (delete)\nYour cleaning script file is how you will load and clean your data. Here is an example of how to use it:\nYou should never use absolute paths (eg. /Users/danielsussman/path/to/project/ or C:\\MA415\\\\Final_Project\\).\nYou might consider using the here function from the here package to avoid path problems.\n\n\nLoad and clean data script\nThe idea behind this file is that someone coming to your website could largely replicate your analyses after running this script on the original data sets to clean them. This file might create a derivative data set that you then use for your subsequent analysis. Note that you don’t need to run this script from every post/page. Instead, you can load in the results of this script, which could be plain text files or .RData files. In your data page you’ll describe how these results were created. If you have a very large data set, you might save smaller data sets that you can use for exploration purposes. To link to this file, you can use [cleaning script](/scripts/load_and_clean_data.R) wich appears as cleaning script."
  },
  {
    "objectID": "data.html#rubric-on-this-page",
    "href": "data.html#rubric-on-this-page",
    "title": "Data",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nDescribe where/how to find data.\n\nYou must include a link to the original data source(s). Make sure to provide attribution to those who collected the data.\nWhy was the data collected/curated? Who put it together? (This is important, if you don’t know why it was collected then that might not be a good dataset to look at.\n\nDescribe the different data files used and what each variable means.\n\nIf you have many variables then only describe the most relevant ones and summarize the rest.\n\nDescribe any cleaning you had to do for your data.\n\nYou must include a link to your load_and_clean_data.R file.\nRename variables and recode factors to make data more clear.\nAlso, describe any additional R packages you used outside of those covered in class.\nDescribe and show code for how you combined multiple data files and any cleaning that was necessary for that.\nSome repetition of what you do in your load_and_clean_data.R file is fine and encouraged if it helps explain what you did.\n\nOrganization, clarity, cleanliness of the page\n\nMake sure to remove excessive warnings, use clean easy-to-read code (without side scrolling), organize with sections, use bullets and other organization tools, etc.\nThis page should be self-contained."
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "Analysis",
    "section": "",
    "text": "This comes from the file analysis.qmd.\nWe describe here our detailed data analysis. This page will provide an overview of what questions you addressed, illustrations of relevant aspects of the data with tables and figures, and a statistical model that attempts to answer part of the question. You’ll also reflect on next steps and further analysis.\nThe audience for this page is someone like your class mates, so you can expect that they have some level of statistical and quantitative sophistication and understand ideas like linear and logistic regression, coefficients, confidence intervals, overfitting, etc.\nWhile the exact number of figures and tables will vary and depend on your analysis, you should target around 5 to 6. An overly long analysis could lead to losing points. If you want you can link back to your blog posts or create separate pages with more details.\nThe style of this paper should aim to be that of an academic paper. I don’t expect this to be of publication quality but you should keep that aim in mind. Avoid using “we” too frequently, for example “We also found that …”. Describe your methodology and your findings but don’t describe your whole process."
  },
  {
    "objectID": "analysis.html#note-on-attribution",
    "href": "analysis.html#note-on-attribution",
    "title": "Analysis",
    "section": "Note on Attribution",
    "text": "Note on Attribution\nIn general, you should try to provide links to relevant resources, especially those that helped you. You don’t have to link to every StackOverflow post you used but if there are explainers on aspects of the data or specific models that you found helpful, try to link to those. Also, try to link to other sources that might support (or refute) your analysis. These can just be regular hyperlinks. You don’t need a formal citation.\nIf you are directly quoting from a source, please make that clear. You can show quotes using &gt; like this\n&gt; To be or not to be.\n\nTo be or not to be."
  },
  {
    "objectID": "analysis.html#rubric-on-this-page",
    "href": "analysis.html#rubric-on-this-page",
    "title": "Analysis",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nIntroduce what motivates your Data Analysis (DA)\n\nWhich variables and relationships are you most interested in?\nWhat questions are you interested in answering?\nProvide context for the rest of the page. This will include figures/tables that illustrate aspects of the data of your question.\n\nModeling and Inference\n\nThe page will include some kind of formal statistical model. This could be a linear regression, logistic regression, or another modeling framework.\nExplain the ideas and techniques you used to choose the predictors for your model. (Think about including interaction terms and other transformations of your variables.)\nDescribe the results of your modelling and make sure to give a sense of the uncertainty in your estimates and conclusions.\n\nExplain the flaws and limitations of your analysis\n\nAre there some assumptions that you needed to make that might not hold? Is there other data that would help to answer your questions?\n\nClarity Figures\n\nAre your figures/tables/results easy to read, informative, without problems like overplotting, hard-to-read labels, etc?\nEach figure should provide a key insight. Too many figures or other data summaries can detract from this. (While not a hard limit, around 5 total figures is probably a good target.)\nDefault lm output and plots are typically not acceptable.\n\nClarity of Explanations\n\nHow well do you explain each figure/result?\nDo you provide interpretations that suggest further analysis or explanations for observed phenomenon?\n\nOrganization and cleanliness.\n\nMake sure to remove excessive warnings, hide most or all code, organize with sections or multiple pages, use bullets, etc.\nThis page should be self-contained, i.e. provide a description of the relevant data."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA [46]15 Final Project",
    "section": "",
    "text": "Final Project due May 7, 2024 at 11:59pm.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 5\n\n\n\n\n\n\n\n\n\n\n\nNov 11, 2024\n\n\nGroup 5\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 4\n\n\n\n\n\n\n\n\n\n\n\nOct 30, 2024\n\n\nGroup 5\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 3\n\n\n\n\n\n\n\n\n\n\n\nOct 28, 2024\n\n\nGroup 5\n\n\n\n\n\n\n\n\n\n\n\n\nblog post 2\n\n\n\n\n\n\n\n\n\n\n\nOct 18, 2024\n\n\nGroup 5\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Blog Post\n\n\n\n\n\n\n\n\n\n\n\nOct 11, 2024\n\n\nGroup 5\n\n\n\n\n\n\n\n\n\n\n\n\nExamples\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 26, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\n\n\n\n\n\n\nGetting started\n\n\n\n\n\n\n\n\nDirections to set up your website and create your first post. \n\n\n\n\n\nFeb 23, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Team Meeting\n\n\n\n\n\n\n\n\nThis post details the steps you’ll take for your first team meeting. \n\n\n\n\n\nFeb 21, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-10-28-blog-post-3/Blog_Post_3.html",
    "href": "posts/2024-10-28-blog-post-3/Blog_Post_3.html",
    "title": "Blog Post 3",
    "section": "",
    "text": "if (!dir.exists(\"../ma-4615-fa24-final-project-group-5/dataset\")) {\n  dir.create(\"../ma-4615-fa24-final-project-group-5/dataset\")\n}\n\ncsv_employment_data &lt;- read.csv(\"../ma-4615-fa24-final-project-group-5/dataset/Employment2017.csv\")\n\nsaveRDS(csv_employment_data, \"../ma-4615-fa24-final-project-group-5/dataset/Employment2017.rds\")\n\nemployment_data &lt;- readRDS(\"../ma-4615-fa24-final-project-group-5/dataset/Employment2017.rds\")\n\n\n#summary(employment_data)\nsum(is.na(employment_data))\n\n[1] 25763\n\n\nThere are 25763 missing values. Many asterisks are used to protect individuals (employee or establishment) from the risk of identification. An asterisk is sometimes used to protect a vulnerable cell and other times to safeguard another at-risk cell.\nNext, we create 3 charts to help with data visualization. The first bar chart helps us visualize the 10 different job types labeled in the dataset by summing up all the rows within the given columns starting with “TOTAL_” and finding their percentages. The second bar chart does something similar, but this time we want to see the proportionality of the 7 given race variables disregarding job types. In a future blog post, we will look into their proportionality with the different job types. The third pie chart looks at the gender variation (male/female0 between all jobs and races.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nemployment_data &lt;- readRDS(\"Employment2017.rds\")\nemployment_data[employment_data == \"*\"] &lt;- NA\n\ntotal_columns &lt;- c(\"TOTAL1\", \"TOTAL2\", \"TOTAL3\", \"TOTAL4\", \"TOTAL5\", \"TOTAL6\", \"TOTAL7\", \"TOTAL8\", \"TOTAL9\", \"TOTAL1_2\")\n\nemployment_data[total_columns] &lt;- lapply(employment_data[total_columns], function(x) as.numeric(x))\n\nemployment_data[total_columns] &lt;- \n  lapply(employment_data[total_columns], function(x) replace_na(x, 0))\n\ntotal_counts &lt;- colSums(employment_data[total_columns], na.rm = TRUE)\n\nproportion_df &lt;- data.frame(Job_Type = names(total_counts), Count = total_counts)\n\nproportion_df$Job_Type &lt;- recode(proportion_df$Job_Type,\n  TOTAL1 = \"Senior Officers and Managers\",\n  TOTAL2 = \"Professionals\",\n  TOTAL3 = \"Technicians\",\n  TOTAL4 = \"Sales Workers\",\n  TOTAL5 = \"Clericals\",\n  TOTAL6 = \"Craft\",\n  TOTAL7 = \"Operatives\",\n  TOTAL8 = \"Laborers\",\n  TOTAL9 = \"Services\",\n  TOTAL1_2 = \"Mid Officers and Managers\"\n)\n\nproportion_df &lt;- proportion_df %&gt;%\n  mutate(Proportion = Count / sum(Count))\n\nggplot(proportion_df, aes(x = Job_Type, y = Proportion, fill = Job_Type)) +\n  geom_bar(stat = \"identity\") +  \n  labs(title = \"Proportionality of Jobs by Type\", \n       x = \"Job Type\", \n       y = \"Proportion\") +\n  theme_gray() +  \n  scale_y_continuous(labels = scales::percent) +  \n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 45, hjust = 1)) \n\n\n\n\n\n\n\n\n\nrace_columns &lt;- c(\"WHT10\", \"BLKT10\", \"HISPT10\", \"ASIANT10\", \"AIANT10\", \"NHOPIT10\", \"TOMRT10\")\n\nemployment_data[race_columns] &lt;- lapply(employment_data[race_columns], function(x) as.numeric(x))\n\nemployment_data[race_columns] &lt;- \n  lapply(employment_data[race_columns], function(x) replace_na(x, 0))\n\ntotal_race_counts &lt;- colSums(employment_data[race_columns], na.rm = TRUE)\n\nrace_proportion_df &lt;- data.frame(Race = names(total_race_counts), Count = total_race_counts)\n\nrace_proportion_df$Race &lt;- recode(race_proportion_df$Race,\n  WHT10 = \"White\",\n  BLKT10 = \"Black or African American\",\n  HISPT10 = \"Hispanic\",\n  ASIANT10 = \"Asian\",\n  AIANT10 = \"American Indian or Alaska Native\",\n  NHOPIT10 = \"Native Hawaiian or Other Pacific Islander\",\n  TOMRT10 = \"Two or more Races\"\n)\n\nrace_proportion_df &lt;- race_proportion_df %&gt;%\n  mutate(Proportion = Count / sum(Count))\n\nggplot(race_proportion_df, aes(x = Race, y = Proportion, fill = Race)) +\n  geom_bar(stat = \"identity\") +  \n  labs(title = \"Proportionality of Race\", \n       x = \"Race\", \n       y = \"Proportion\") +\n  theme_gray() +  \n  scale_y_continuous(labels = scales::percent) +  \n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 45, hjust = 1)) \n\n\n\n\n\n\n\n\n\ngender_columns &lt;- c(\"MT10\", \"FT10\")\n\nemployment_data[gender_columns] &lt;- lapply(employment_data[gender_columns], function(x) as.numeric(x))\n\nemployment_data[gender_columns] &lt;- \n  lapply(employment_data[gender_columns], function(x) replace_na(x, 0))\n\ntotal_gender_counts &lt;- colSums(employment_data[gender_columns], na.rm = TRUE)\n\ngender_proportion_df &lt;- data.frame(Gender = names(total_gender_counts), Count = total_gender_counts)\n\ngender_proportion_df$Gender &lt;- recode(gender_proportion_df$Gender,\n  MT10 = \"Male\", FT10 = \"Female\")\n\ngender_proportion_df &lt;- gender_proportion_df %&gt;%\n  mutate(Proportion = Count / sum(Count),\n         Percentage = Proportion * 100)  \n\nggplot(gender_proportion_df, aes(x = \"\", y = Proportion, fill = Gender)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(\"y\") + \n  labs(title = \"Proportionality of Gender\", \n       fill = \"Gender\") +\n  theme_gray() +  \n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        axis.ticks = element_blank(),\n        axis.text = element_blank()) +\n  geom_text(aes(label = paste0(round(Percentage, 1), \"%\")), \n            position = position_stack(vjust = 0.5)) \n\n\n\n\n\n\n\n\nNext, we create our cleaned folder. It is also included in the data.qmd as well as the scripts/cleaned_data file.\n\nlibrary(dplyr)\nlibrary(tidyselect)\n\nemployment_data &lt;- readRDS(\"Employment2017.rds\")\n\ncleaned_data &lt;- employment_data %&gt;%\n  select(\n    Nation, Region, Division, State, CBSA, County, NAICS2, NAICS2_Name, NAICS3, NAICS3_Name, Establishments,\n    matches(\"^WHT_([1-9]|1_2)$\"),\n    matches(\"^BLKT_([1-9]|1_2)$\"),\n    matches(\"^HISPT_([1-9]|1_2)$\"),\n    matches(\"^ASIANT_([1-9]|1_2)$\"),\n    matches(\"^AIANT_([1-9]|1_2)$\"),\n    matches(\"^NHOPIT_([1-9]|1_2)$\"),\n    matches(\"^TOMRT_([1-9]|1_2)$\"),\n    matches(\"^MT_([1-9]|1_2)$\"),\n    matches(\"^FT_([1-9]|1_2)$\")\n  )\n\nif (!dir.exists(\"../ma-4615-fa24-final-project-group-5/dataset\")) {\n  dir.create(\"../ma-4615-fa24-final-project-group-5/dataset\", recursive = TRUE)\n}\n\nsaveRDS(cleaned_data, \"../ma-4615-fa24-final-project-group-5/dataset/Cleaned_Employment2017.rds\")\n\nData for Equity\nTransparency\nTransparency is a critical component in equitable data analysis. In our project, being transparent would provide us with any potential limitations in the dataset, such as the lack of representation for smaller sized companies. This exclusion could skew our analysis, if smaller sized companies employ more people from certain demographic groups or adhere to different hiring practices.\nPrivacy and Data Protection\nIn our dataset, the use of asterisks (*) in cells are designed to prevent individual identification, which aligns with the Privacy and Data Protection principle by protecting vulnerable populations. Doing so avoids any attempts to infer or disaggregate data that could lead to re-identifying individuals or small groups, particularly in fields where there is limited representation (e.g., certain job categories or minority groups). This respect for privacy aligns with data equity by fostering a safe environment for marginalized communities.\nInclusivity and Representativeness\nIn our dataset, focusing on medium sized companies disregards the smaller sized companies, which could include potentially significance in minority or gender-represented employment. It is important to include all data as it better captures a representation of the dataset for all demographic groups. By including data on smaller sized companies, we are able to broaden the analysis and provide a more complete picture of industry disparities and representation across all workforce segments. This is particularly significant as many family businesses, which fall beyond the purview of our dataset, tend to be minority owned."
  },
  {
    "objectID": "posts/2024-10-11-first-blog-post/first-blog-post.html",
    "href": "posts/2024-10-11-first-blog-post/first-blog-post.html",
    "title": "First Blog Post",
    "section": "",
    "text": "NYPD Arrest Data (Year to Date)\n\nSource: https://data.cityofnewyork.us/Public-Safety/NYPD-Arrest-Data-Year-to-Date-/uip8-fykc/about_data Columns:19\nRows: This dataset includes a breakdown of arrests in New York City, with thousands of rows representing individual arrests over the course of the current year.\nDescription and Origin: The dataset is manually extracted and reviewed by the Office of Management Analysis and Planning. It includes information such as arrest records, crime type, and suspect demographics. In addition, it provides a breakdown of the police enforcement activity in NYC, giving insights into the types of crimes and the frequency.\nMain Questions: Do arrest patterns vary significantly by race across different boroughs or precincts? Are there disparities in the types of crimes different racial groups are arrested for (felonies vs. misdemeanors)? How do demographic factors like age and sex influence arrest rates by race?\nChallenges: While the dataset has lots of information, it requires us to clean and organize the data effectively when working with location-based data. Additionally, the coordinates need to be interpreted correctly, which makes ensuring accurate data more challenging. Since we are looking at racial disparities, it is essential to recognize that multiple factors influence the data beyond race alone. In other words, we need to control other factors to isolate the specific impact of race on arrest outcomes.\n\nChicago Violence Reduction Data Source: https://catalog.data.gov/dataset/violence-reduction-victim-demographics-aggregated\n\nColumns: 11 Rows: Each row is aggregated up to victimization type, age group, sex, race, and whether the victimization was domestic-related. There are 54756 rows.\nDescription and Origin: This dataset contains aggregate data on violent index victimizations at the quarter level of each year (i.e., January – March, April – June, July – September, October – December), from 2001 to the present (1991 to present for Homicides), with a focus on those related to gun violence. This dataset includes only those index crimes that involve bodily harm or the threat of bodily harm and are reported to the Chicago Police Department (CPD). Index crimes are 10 crime types selected by the FBI (codes 1-4) for special focus due to their seriousness and frequency.\nMain Questions: How does the number of victims vary across age groups, sex, and race? Are certain quarters of the year consistently getting more victims with certain demographic perpetrators, and do these patterns change year-over-year? Are domestic-related incidents more prevalent in any particular index crime type or demographic group?\nChallenge: One challenge we foresee is potential coding logic. The quarterly system and large data quantity will be something to work through. Another thing to note is that the dataset is updated daily, so as long as nothing drastic pops up, our analysis will remain smooth running. Working with multiple variables can be confusing, but with time, we should be able to overcome that.\n\nJob Patterns For Minorities And Women In Private Industry, 2017 EEO-1 National Aggregate Report\n\nSource: https://catalog.data.gov/dataset/job-patterns-for-minorities-and-women-in-private-industry-2017-eeo-1-national-aggregate-re Columns: 12 (275 total) Rows: 43729\nDescription and Origin: As part of its mandate under Title VII of the Civil Rights Act of 1964, as amended, the Equal Employment Opportunity Commission requires periodic reports from public and private employers, and unions and labor organizations which indicate the composition of their work forces by sex and by race/ethnic category. Key among these reports is the EEO-1, which is collected annually from Private employers with 100 or more employees or federal contractors with 50 more employees.\nMain Questions: How does employment by race (WHT10, BLKT10, HISPT10, ASIANT10, AIANT10, NHOPIT10, TOMRT10) vary across different industries or geographic regions? How does the racial composition of the workforce differ by industry? Are there significant employment disparities between racial groups within the same industry or region?\nChallenges: This dataset would require high-dimensional analysis which may be difficult with what we learned in class. Another challenge is that much of the data is aggregated or has aggregated variable which may make it difficult to make deeper analyses."
  },
  {
    "objectID": "posts/2023-10-15-getting-started/getting-started.html",
    "href": "posts/2023-10-15-getting-started/getting-started.html",
    "title": "Getting started",
    "section": "",
    "text": "Below, the items marked with [[OP]] should only be done by one person on the team.\n\nTo get started\n\n[[OP]] One person from the team should click the Github Classroom link on Teams.\n[[OP]] That person types in the group name for their group.\nThe rest of the team now clicks the Github Classroom link and selects their team from the dropdown list.\nFinally, each of you can clone the repository to your laptop like a normal assignment.\n\n\n\nSetting up the site\n\n[[OP]] Open the terminal and run quarto publish gh-pages.\n[[OP]] Select Yes to the prompt:  ? Publish site to https://sussmanbu.github.io/ma4615-fa23-final-project-TEAMNAME/ using gh-pages? (Y/n)\n[[OP]] Wait for the process to finish.\nOnce it is done, you can go to the URL it asked you about to see your site.\n\nNote: This is the process you will use every time you want to update your published site. Make sure to always follow the steps below for rendering, previewing, and committing your changes before doing these publish steps. Anyone can publish in the future.\n\n\nCustomize your site\n\n[[OP]] Open the _quarto.yml file and update the title to include your team name.\n[[OP]] Go to the about.qmd and remove the TF’s and professor’s names.\nadd your own along with a short introduction and a link to your Github user page.\n[[OP]] Render the site.\n[[OP]] Check and make sure you didn’t get any errors.\n[[OP]] Commit your changes and push.\n[[OP]] Repeat the steps under Setting up your site.\n\nOnce one person is done with this, each teammate in the group can, in turn, repeat steps 3-7. Before doing so, make sure to pull the changes from teammates before starting to make new changes. (We’ll talk soon about ways to organize your work and resolve conflicts.)\n\n\nStart your first post\n\nTo start your first post first, run remotes::install_github(\"sussmanbu/quartopost\") in your Console.\n[[OP]] Run quartopost::quartopost() (or click Addins-&gt;Create Quarto Post, or use C-Shift-P, type “Create Quarto” and press enter to run the command).\n\nNow you can start working on your post. You’ll want to render your post to see what it will look like on the site.\n\nEvery time you want to make a new post, you can repeat step 2 above.\nWhen you want to publish your progress, follow steps 4-7 from Customize your site.\n\nFinally, make sure to read through everything on this site which has the directions and rubric for the final project."
  },
  {
    "objectID": "posts/2024-10-18-blog-post-2/blog-post-2.html",
    "href": "posts/2024-10-18-blog-post-2/blog-post-2.html",
    "title": "blog post 2",
    "section": "",
    "text": "Origin: This dataset was published by the US Equal Employment Opportunity Commission and is maintained by Daniel McGregor. As part of its mandate under Title VII of the Civil Rights Act of 1964, as amended, the Equal Employment Opportunity Commission requires periodic reports from public and private employers, unions, and labor organizations that indicate the composition of their workforce by sex and by race/ethnic category. Among these reports, the EEO-1 is collected annually from Private employers with 100 or more employees or federal contractors with 50 more employees.\nProblems with Data: The ‘Aggregate’ option shows the sum of employee counts for all other options in the dropdown. This option is offered to maximize the domain of publishable data. Since the ‘Aggregate’ option includes the employee count of alternatives presented within a given dropdown, this option should not be selected if any other option is selected within the same filter. Therefore, uncheck the ‘Aggregate’ option from a filter dropdown while selecting any other option from the same dropdown for generating reports with unduplicated employee counts. With legally mandated reporting, we assume that the data gathered through the census is thorough enough that there are no concerns about selection bias; one possible area of bias is the fact that the data disregards companies with less than 100 employees; this may cause skew with demographics that might have significant employment in smaller companies, like family-owned businesses.\nImportance of Data:\nThe data’s importance is to distinguish the employment disparities between racial groups within the same industry or region. The data de-identification methodology was developed to ensure the safeguarding of identifiable information to fulfill legal requirements under Section 709 (e) of Title VII of the Civil Rights Act of 1964, as amended by the Equal Employment Opportunity Act of 1972. Aggregated counts of employers and employees at each dimension (geography x job category x NAICS-2 x NAICS-3 x race x sex) were processed through primary and secondary suppression steps to protect identifying information. The programming codes were applied to each year’s data separately."
  },
  {
    "objectID": "posts/2024-11-08-blog-post-4/Blog_Post_4.html",
    "href": "posts/2024-11-08-blog-post-4/Blog_Post_4.html",
    "title": "Blog Post 4",
    "section": "",
    "text": "Our initial exploratory data analysis involved some rudimentary breakdowns between the labor statistics and two metrics, particularly race and gender. Utilizing the provided categories of American Indigenous, Asian, Black, Hispanic, Native Hawaiian, two or more, and White, we created a facet showing the racial distributions among the job categories: 1 (senior off and managers), 2 (professionals) 3 (technicians), 4 (sales workers), 5 (clericals), 6 (craft), 7 (operatives), 8 (labors), 9 (service) and 1_2 (mid off and managers). Some more cleaning may be needed to reduce redundant or blank values, but a cursory examination shows approximate parity between various job distributions, with the exception of craft, for which distributions are more uniform. Reducing the seeming uniformity of the different charts may be a matter of controlling for the proportion of the population occupied by each race category, to get more proportionate metrics that are not overshadowed by the gross proportions of each race as represented by the total population. Additionally, a further inquiry into the exact meaning and jobs entailed by the descriptive numbers used by NAICS may be useful, as we find further data sets with descriptive statistics like wages and benefits for particular jobs that need to be linked to the very general categories described by our original dataset.\nWe also performed a similar breakdown by gender, although in this category it was also difficult to detect any significant discrepancies between various jobs and their gender distribution, contrary to popular notions of gender divides in certain jobs, which may warrant a further inquiry into the source and exact meaning of the data. Like with the racial breakdowns, it may also be useful to derive proportions rather than raw numbers to better account for population differences.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\nlibrary(tidyr)\n\n# Read data\ncleaned_data &lt;- readRDS(\"../ma-4615-fa24-final-project-group-5/dataset/Cleaned_Employment2017.rds\")\n\n# Pivot to long format, excluding MT and FT\nlong_data &lt;- cleaned_data %&gt;%\n  pivot_longer(\n    cols = matches(\"^(WHT|BLKT|HISPT|ASIANT|AIANT|NHOPIT|TOMRT)([1-9]|1_2)?$\"),\n    names_to = c(\"Race\", \"JobType\"),\n    names_pattern = \"^(WHT|BLKT|HISPT|ASIANT|AIANT|NHOPIT|TOMRT)([1-9]|1_2)?$\",\n    values_to = \"Count\"\n  ) %&gt;%\n  filter(!is.na(JobType) & !is.na(Race))\n\n# Ensure only specified Job Types are included\nvalid_job_types &lt;- c(\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"1_2\")\nfiltered_data &lt;- long_data %&gt;%\n  filter(JobType %in% valid_job_types) %&gt;%\n  mutate(\n    Count = gsub(\"[^0-9.-]\", \"\", Count),  # Clean non-numeric characters\n    Count = as.numeric(Count),            # Convert to numeric\n    Count = ifelse(is.na(Count), 0, Count) # Replace NA with 0\n  )\n\n# Plotting\nggplot(filtered_data, aes(x = Race, y = Count, fill = Race)) +\n  geom_bar(stat = \"identity\") +\n  facet_wrap(~ JobType, scales = \"free_y\") +\n  theme_gray() +\n  labs(\n    title = \"Proportional Representation by Job Type and Race\",\n    x = \"Race\",\n    y = \"Count\"\n  ) +\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 5)) +\n  theme(\n    legend.position = \"none\",\n    strip.text = element_text(size = 10, face = \"bold\"),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    axis.text.y = element_text(size = 8)\n  )\n\n\n\n\n\n\n\n\n\nprint(long_data)\n\n# A tibble: 3,060,960 × 34\n   Nation        Region Division State CBSA  County NAICS2 NAICS2_Name NAICS3\n   &lt;chr&gt;         &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;        &lt;int&gt;\n 1 United States \"\"     \"\"       \"\"    \"\"    \"\"         NA \"\"              NA\n 2 United States \"\"     \"\"       \"\"    \"\"    \"\"         NA \"\"              NA\n 3 United States \"\"     \"\"       \"\"    \"\"    \"\"         NA \"\"              NA\n 4 United States \"\"     \"\"       \"\"    \"\"    \"\"         NA \"\"              NA\n 5 United States \"\"     \"\"       \"\"    \"\"    \"\"         NA \"\"              NA\n 6 United States \"\"     \"\"       \"\"    \"\"    \"\"         NA \"\"              NA\n 7 United States \"\"     \"\"       \"\"    \"\"    \"\"         NA \"\"              NA\n 8 United States \"\"     \"\"       \"\"    \"\"    \"\"         NA \"\"              NA\n 9 United States \"\"     \"\"       \"\"    \"\"    \"\"         NA \"\"              NA\n10 United States \"\"     \"\"       \"\"    \"\"    \"\"         NA \"\"              NA\n# ℹ 3,060,950 more rows\n# ℹ 25 more variables: NAICS3_Name &lt;chr&gt;, Establishments &lt;int&gt;, MT1 &lt;chr&gt;,\n#   MT2 &lt;chr&gt;, MT3 &lt;chr&gt;, MT4 &lt;chr&gt;, MT5 &lt;chr&gt;, MT6 &lt;chr&gt;, MT7 &lt;chr&gt;,\n#   MT8 &lt;chr&gt;, MT9 &lt;chr&gt;, MT1_2 &lt;chr&gt;, FT1 &lt;chr&gt;, FT2 &lt;chr&gt;, FT3 &lt;chr&gt;,\n#   FT4 &lt;chr&gt;, FT5 &lt;chr&gt;, FT6 &lt;chr&gt;, FT7 &lt;chr&gt;, FT8 &lt;chr&gt;, FT9 &lt;chr&gt;,\n#   FT1_2 &lt;chr&gt;, Race &lt;chr&gt;, JobType &lt;chr&gt;, Count &lt;chr&gt;\n\n\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Pivot to long format\nlong_data &lt;- cleaned_data %&gt;%\n  pivot_longer(\n    cols = matches(\"^(Male|Female|MT|FT)[1-9](_2)?$\"),\n    names_to = c(\"Gender\", \"JobType\"),\n    names_pattern = \"^(Male|Female|MT|FT)([1-9]|1_2)?$\",\n    values_to = \"Count\"\n  ) %&gt;%\n  filter(!is.na(JobType) & !is.na(Gender))\n\n# Ensure 'Count' is numeric, handling non-numeric values\nlong_data &lt;- long_data %&gt;%\n  mutate(\n    Count = as.numeric(Count),             # Convert 'Count' to numeric\n    Count = ifelse(is.na(Count), 0, Count)  # Replace any NA with 0\n  )\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `Count = as.numeric(Count)`.\nCaused by warning:\n! NAs introduced by coercion\n\n# Filter for valid job types\nvalid_job_types &lt;- c(\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"1_2\")\nfiltered_data &lt;- long_data %&gt;%\n  filter(JobType %in% valid_job_types) %&gt;%\n  group_by(JobType, Gender) %&gt;%\n  mutate(\n    Total = sum(Count, na.rm = TRUE),  # Total count for each JobType\n    Percent = Count / Total * 100      # Calculate percentage\n  ) %&gt;%\n  ungroup()\n\n# Plotting: Show percentages instead of counts\nggplot(filtered_data, aes(x = Gender, y = Percent, fill = Gender)) +\n  geom_bar(stat = \"identity\") +\n  facet_wrap(~ JobType, scales = \"free_y\") +\n  theme_gray() +\n  labs(\n    title = \"Proportional Representation by Job Type and Gender\",\n    x = \"Gender\",\n    y = \"Percentage\"\n  ) +\n  theme(\n    legend.position = \"none\",              # Remove legend\n    strip.text = element_text(size = 10, face = \"bold\"),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    axis.text.y = element_text(size = 8)\n  )"
  },
  {
    "objectID": "posts/2023-10-13-first-team-meeting/first-team-meeting.html",
    "href": "posts/2023-10-13-first-team-meeting/first-team-meeting.html",
    "title": "First Team Meeting",
    "section": "",
    "text": "These are the steps that you will take today to get started on your project. Today, you will just be brainstorming, and then next week, you’ll get started on the main aspects of the project.\n\nStart by introducing yourselves to each other. I also recommend creating a private channel on Microsoft Teams with all your team members. This will be a place that you can communicate and share ideas, code, problems, etc.\nDiscuss what aspects of the project each of you are more or less excited about. These include\n\nCollecting, cleaning, and munging data ,\nStatistical Modeling,\nVisualization,\nWriting about analyses, and\nManaging and reviewing team work.\n\nBased on this, discuss where you feel your strengths and weaknesses might be.\nNext, start brainstorming questions you hope to answer as part of this project. This question should in some way be addressing issues around racial disparities. The questions you come up with should be at the level of the question we started with when exploring the HMDA data. (“Are there differences in the ease of securing a loan based on the race of the applicant?”) You’ll revise your questions a lot over the course of the project. Come up with a few questions that your group might be interested in exploring.\nBased on these questions, start looking around for data that might help you analyze this. If you are looking at U.S. based data, data.gov is a good source and if you are looking internationally, I recommend checking out the World Bank. Also, try Googling for data. Include “data set” or “dataset” in your query. You might even include “CSV” or some other format. Using “data” by itself in your query often doesn’t work too well. Spend some time searching for data and try to come up with at least three possible data sets. (For your first blog post, you’ll write short proposals about each of them that I’ll give feedback on.)\nCome up with a team name. Next week, I’ll provide the Github Classroom assignment that will be where you work on your final project and you’ll have to have your team name finalized by then. Your project will be hosted online at the website with a URL like sussmanbu.github.io/ma4615-fa23-final-project-TEAMNAME.\n\nNext time, you’ll get your final project website set up and write your first blog post."
  },
  {
    "objectID": "posts/2024-11-11-blog-post-5/Blog Post 5.html",
    "href": "posts/2024-11-11-blog-post-5/Blog Post 5.html",
    "title": "Blog Post 5",
    "section": "",
    "text": "Previously in Blog Post 4, we explored two breakdowns of the 2017 dataset, focusing on race and gender. For Blog Post 5, our goal is to extend this analysis to the 2022 dataset, creating similar breakdowns for comparison. This will allow us to visually contrast the 2017 and 2022 data.\nSince we already have 2017 images in Blog Post 3 and 4, this post will be dedicated to 2022 coding scripts.\nIn addition, we have found another dataset that details the wage data associated with all of the jobs listed under the NAICS standard of categorization, logging average hourly wages in October 2023, and August, September, and October 2024. Although the format does not make direct matching to our existing dataset easy, we hope to parse through the data (possibly manually) and use it to assign wage values to our existing race and gender distributions for the different kinds of employment. This information can be useful in exploring potential earning gaps between groups, as well as examining the change in earnings over time. By the time we complete processing the data, we hope to have the information included here as an additional column of our table that we can use in our analysis. Further exploration is warranted in the feasibility of transferring the online table into some kind of csv that can be read into an R script directly.\nHere is the link for the wage data context: https://www.bls.gov/web/empsit/ceseeb3a.htm\n\n# Getting the downloaded file for everyone to access\n#library(readxl)\n#data_2022 &lt;- read_excel(\"~/Downloads/EEO1 2022 PUF.xlsx\")\n#write.csv(data_2022, \"dataset/EEO1_2022_PUF.csv\", row.names = FALSE)\n#saveRDS(data_2022, \"dataset/EEO1_2022_PUF.rds\")\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(here)\n\nhere() starts at /Users/emilymusiclin/Downloads/CAS MA 415/ma-4615-fa24-final-project-group-5\n\nemployment_2022 &lt;- readRDS(\"dataset/EEO1_2022_PUF.rds\")\nemployment_2022[employment_2022 == \"*\"] &lt;- NA\n\ntotal_columns &lt;- c(\"TOTAL1\", \"TOTAL2\", \"TOTAL3\", \"TOTAL4\", \"TOTAL5\", \"TOTAL6\", \"TOTAL7\", \"TOTAL8\", \"TOTAL9\", \"TOTAL1_2\")\n\nemployment_2022[total_columns] &lt;- lapply(employment_2022[total_columns], function(x) as.numeric(x))\n\nemployment_2022[total_columns] &lt;- \n  lapply(employment_2022[total_columns], function(x) replace_na(x, 0))\n\ntotal_counts &lt;- colSums(employment_2022[total_columns], na.rm = TRUE)\n\nproportion_df &lt;- data.frame(Job_Type = names(total_counts), Count = total_counts)\n\nproportion_df$Job_Type &lt;- recode(proportion_df$Job_Type,\n  TOTAL1 = \"Senior Officers and Managers\",\n  TOTAL2 = \"Professionals\",\n  TOTAL3 = \"Technicians\",\n  TOTAL4 = \"Sales Workers\",\n  TOTAL5 = \"Clericals\",\n  TOTAL6 = \"Craft\",\n  TOTAL7 = \"Operatives\",\n  TOTAL8 = \"Laborers\",\n  TOTAL9 = \"Services\",\n  TOTAL1_2 = \"Mid Officers and Managers\"\n)\n\nproportion_df &lt;- proportion_df %&gt;%\n  mutate(Proportion = Count / sum(Count))\n\nggplot(proportion_df, aes(x = Job_Type, y = Proportion, fill = Job_Type)) +\n  geom_bar(stat = \"identity\") +  \n  labs(title = \"Proportionality of Jobs by Type\", \n       x = \"Job Type\", \n       y = \"Proportion\") +\n  theme_gray() +  \n  scale_y_continuous(labels = scales::percent) +  \n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 45, hjust = 1)) \n\n\n\n\n\n\n\n\n\nrace_columns &lt;- c(\"WHT10\", \"BLKT10\", \"HISPT10\", \"ASIANT10\", \"AIANT10\", \"nhopiT10\", \"tomrT10\")\n\n\nemployment_2022[race_columns] &lt;- lapply(employment_2022[race_columns], function(x) as.numeric(x))\n\nemployment_2022[race_columns] &lt;- \n  lapply(employment_2022[race_columns], function(x) replace_na(x, 0))\n\ntotal_race_counts &lt;- colSums(employment_2022[race_columns], na.rm = TRUE)\n\nrace_proportion_df &lt;- data.frame(Race = names(total_race_counts), Count = total_race_counts)\n\nrace_proportion_df$Race &lt;- recode(race_proportion_df$Race,\n  WHT10 = \"White\",\n  BLKT10 = \"Black or African American\",\n  HISPT10 = \"Hispanic\",\n  ASIANT10 = \"Asian\",\n  AIANT10 = \"American Indian or Alaska Native\",\n  nhopiT10 = \"Native Hawaiian or Other Pacific Islander\",\n  tomrT10 = \"Two or more Races\"\n)\n\nrace_proportion_df &lt;- race_proportion_df %&gt;%\n  mutate(Proportion = Count / sum(Count))\n\nggplot(race_proportion_df, aes(x = Race, y = Proportion, fill = Race)) +\n  geom_bar(stat = \"identity\") +  \n  labs(title = \"Proportionality of Race\", \n       x = \"Race\", \n       y = \"Proportion\") +\n  theme_gray() +  \n  scale_y_continuous(labels = scales::percent) +  \n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 45, hjust = 1)) \n\n\n\n\n\n\n\n\n\ngender_columns &lt;- c(\"MT10\", \"FT10\")\n\nemployment_2022[gender_columns] &lt;- lapply(employment_2022[gender_columns], function(x) as.numeric(x))\n\nemployment_2022[gender_columns] &lt;- \n  lapply(employment_2022[gender_columns], function(x) replace_na(x, 0))\n\ntotal_gender_counts &lt;- colSums(employment_2022[gender_columns], na.rm = TRUE)\n\ngender_proportion_df &lt;- data.frame(Gender = names(total_gender_counts), Count = total_gender_counts)\n\ngender_proportion_df$Gender &lt;- recode(gender_proportion_df$Gender,\n  MT10 = \"Male\", FT10 = \"Female\")\n\ngender_proportion_df &lt;- gender_proportion_df %&gt;%\n  mutate(Proportion = Count / sum(Count),\n         Percentage = Proportion * 100)  \n\nggplot(gender_proportion_df, aes(x = \"\", y = Proportion, fill = Gender)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(\"y\") + \n  labs(title = \"Proportionality of Gender\", \n       fill = \"Gender\") +\n  theme_gray() +  \n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        axis.ticks = element_blank(),\n        axis.text = element_blank()) +\n  geom_text(aes(label = paste0(round(Percentage, 1), \"%\")), \n            position = position_stack(vjust = 0.5)) \n\n\n\n\n\n\n\n\n\nlibrary(dplyr)\nlibrary(tidyselect)\n\nemployment_2022 &lt;- readRDS(\"dataset/EEO1_2022_PUF.rds\")\n\nemployment_2022 &lt;- employment_2022 %&gt;%\n  rename_with(toupper)\n\ncleaned_2022 &lt;- employment_2022 %&gt;%\n  select(\n    NATION, REGION, DIVISION, STATE, CBSA, COUNTY, NAICS2, NAICS2_NAME, NAICS3, NAICS3_NAME, ESTABLISHMENTS,\n    matches(\"^(WHT|BLKT|HISPT|ASIANT|AIANT|NHOPIT|TOMRT|MT|FT)[1-9](_2)?$\")\n  )\n\nif (!dir.exists(\"../ma-4615-fa24-final-project-group-5/dataset\")) {\n  dir.create(\"../ma-4615-fa24-final-project-group-5/dataset\", recursive = TRUE)\n}\n\nsaveRDS(cleaned_2022, \"../ma-4615-fa24-final-project-group-5/dataset/Cleaned_Employment2022.rds\")\ncleaned_2022_dataset &lt;- readRDS(\"dataset/Cleaned_Employment2022.rds\")\n\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\n\n# Read the cleaned data\ncleaned_2022 &lt;- readRDS(\"../ma-4615-fa24-final-project-group-5/dataset/Cleaned_Employment2022.rds\")\n\n# Pivot to long format, including only specified race and job types\nlong_data_race &lt;- cleaned_2022 %&gt;%\n  pivot_longer(\n    cols = matches(\"^(WHT|BLKT|HISPT|ASIANT|AIANT|NHOPIT|TOMRT)([1-9]|1_2)?$\"),\n    names_to = c(\"Race\", \"JobType\"),\n    names_pattern = \"^(WHT|BLKT|HISPT|ASIANT|AIANT|NHOPIT|TOMRT)([1-9]|1_2)?$\",\n    values_to = \"Count\"\n  ) %&gt;%\n  filter(!is.na(JobType) & !is.na(Race))\n\n# Ensure only specified Job Types are included\nvalid_job_types &lt;- c(\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"1_2\")\nfiltered_data_race &lt;- long_data_race %&gt;%\n  filter(JobType %in% valid_job_types) %&gt;%\n  mutate(\n    Count = gsub(\"[^0-9.-]\", \"\", Count),  # Clean non-numeric characters\n    Count = as.numeric(Count),            # Convert to numeric\n    Count = ifelse(is.na(Count), 0, Count) # Replace NA with 0\n  )\n\n# Add descriptive labels for Job Types and set factor order\nfiltered_data_race &lt;- filtered_data_race %&gt;%\n  mutate(\n    JobTypeLabel = recode(JobType,\n      \"1\" = \"Senior Off and Managers\",\n      \"2\" = \"Professionals\",\n      \"3\" = \"Technicians\",\n      \"4\" = \"Sales Workers\",\n      \"5\" = \"Clericals\",\n      \"6\" = \"Craft\",\n      \"7\" = \"Operatives\",\n      \"8\" = \"Laborers\",\n      \"9\" = \"Services\",\n      \"1_2\" = \"Mid Off and Managers\"\n    ),\n    JobTypeLabel = factor(JobTypeLabel, levels = c(\n      \"Senior Off and Managers\", \"Professionals\", \"Technicians\",\n      \"Sales Workers\", \"Clericals\", \"Craft\", \"Operatives\", \"Laborers\", \"Services\", \n      \"Mid Off and Managers\"\n    ))\n  )\n\n# Plotting Race representation with descriptive job type labels\nggplot(filtered_data_race, aes(x = Race, y = Count, fill = Race)) +\n  geom_bar(stat = \"identity\") +\n  facet_wrap(~ JobTypeLabel, scales = \"free_y\") +  # Use JobTypeLabel for custom titles\n  theme_gray() +\n  labs(\n    title = \"Proportional Representation by Job Type and Race (2022)\",\n    x = \"Race\",\n    y = \"Count\"\n  ) +\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 5)) +\n  theme(\n    legend.position = \"none\",\n    strip.text = element_text(size = 10, face = \"bold\"),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    axis.text.y = element_text(size = 8)\n  )\n\n\n\n\n\n\n\n\n\n# Pivot to long format for gender data\nlong_data_gender &lt;- cleaned_2022 %&gt;%\n  pivot_longer(\n    cols = matches(\"^(MT|FT)([1-9]|1_2)?$\"),\n    names_to = c(\"Gender\", \"JobType\"),\n    names_pattern = \"^(MT|FT)([1-9]|1_2)?$\",\n    values_to = \"Count\"\n  ) %&gt;%\n  filter(!is.na(JobType) & !is.na(Gender))\n\n# Ensure 'Count' is numeric, handling non-numeric values\nlong_data_gender &lt;- long_data_gender %&gt;%\n  mutate(\n    Count = as.numeric(Count),             # Convert 'Count' to numeric\n    Count = ifelse(is.na(Count), 0, Count)  # Replace any NA with 0\n  )\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `Count = as.numeric(Count)`.\nCaused by warning:\n! NAs introduced by coercion\n\n# Filter for valid job types and calculate percentages correctly for each gender\nfiltered_data_gender &lt;- long_data_gender %&gt;%\n  filter(JobType %in% valid_job_types) %&gt;%\n  group_by(JobType) %&gt;%\n  mutate(\n    Total = sum(Count, na.rm = TRUE),  # Total count for each JobType and Gender\n    Percent = (Count / Total) * 100      # Calculate percentage within each JobType and Gender\n  ) %&gt;%\n  ungroup()\n\n# Add descriptive labels for Job Types and set factor order\nfiltered_data_gender &lt;- filtered_data_gender %&gt;%\n  mutate(\n    JobTypeLabel = recode(JobType,\n      \"1\" = \"Senior Off and Managers\",\n      \"2\" = \"Professionals\",\n      \"3\" = \"Technicians\",\n      \"4\" = \"Sales Workers\",\n      \"5\" = \"Clericals\",\n      \"6\" = \"Craft\",\n      \"7\" = \"Operatives\",\n      \"8\" = \"Laborers\",\n      \"9\" = \"Services\",\n      \"1_2\" = \"Mid Off and Managers\"\n    ),\n    JobTypeLabel = factor(JobTypeLabel, levels = c(\n      \"Senior Off and Managers\", \"Professionals\", \"Technicians\",\n      \"Sales Workers\", \"Clericals\", \"Craft\", \"Operatives\", \"Laborers\", \"Services\", \n      \"Mid Off and Managers\"\n    ))\n  )\n\n# Plotting Gender representation\nggplot(filtered_data_gender, aes(x = Gender, y = Percent, fill = Gender)) +\n  geom_bar(stat = \"identity\") +\n  facet_wrap(~ JobTypeLabel, scales = \"free_y\") +\n  theme_gray() +\n  labs(\n    title = \"Proportional Representation by Job Type and Gender (2022)\",\n    x = \"Gender\",\n    y = \"Percentage\"\n  ) +\n  theme(\n    legend.position = \"none\",              # Remove legend\n    strip.text = element_text(size = 10, face = \"bold\"),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    axis.text.y = element_text(size = 8)\n  )"
  },
  {
    "objectID": "posts/2023-12-20-examples/examples.html",
    "href": "posts/2023-12-20-examples/examples.html",
    "title": "Examples",
    "section": "",
    "text": "Here are some examples of changing the size of a figure.\n\nplot(1:10)\n\n\n\n\n\n\n\n\n\nplot(1:10)\n\n\n\n\n\n\n\n\nWe can also specify column: screen and out-width: 100% so that the figure will fill the screen. plot in the svg vector graphics file format.\n\nlibrary(ggplot2)\nggplot(pressure, aes(x = temperature, y = pressure)) + geom_point()"
  },
  {
    "objectID": "posts/2023-12-20-examples/examples.html#figure-sizing",
    "href": "posts/2023-12-20-examples/examples.html#figure-sizing",
    "title": "Examples",
    "section": "",
    "text": "Here are some examples of changing the size of a figure.\n\nplot(1:10)\n\n\n\n\n\n\n\n\n\nplot(1:10)\n\n\n\n\n\n\n\n\nWe can also specify column: screen and out-width: 100% so that the figure will fill the screen. plot in the svg vector graphics file format.\n\nlibrary(ggplot2)\nggplot(pressure, aes(x = temperature, y = pressure)) + geom_point()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This comes from the file about.qmd.\nThis is a website for the final project for MA[46]15 Data Science with R by Team TEAMNAME. The members of this team are below.\n\nJay Chiang\nI am a senior studying data science.\n\n\nYichen Li\nStatistic master student\n\n\nGeorge Jiang\nI am a junior studying data science.\n\n\nIsaac Hu\nI am a senior studying computer science\n\n\nEmily Lin\nI am a junior studying math and statistics\n\n\nAbout this Template.\nThis is based off of the standard Quarto website template from RStudio (2023.09.0 Build 463)."
  },
  {
    "objectID": "big_picture.html",
    "href": "big_picture.html",
    "title": "Big Picture",
    "section": "",
    "text": "This comes from the file big_picture.Rmd.\nThink of this page as your 538/Upshot style article. This means that you should try to tell a story through the data and your analysis. Read articles from those sites and similar sites to get a feeling for what they are like. Try to write in the style of a news or popular article. Importantly, this page should be geared towards the general public. You shouldn’t assume the reader understands how to interpret a linear regression or a complicated plot. Focus on interpretation and visualizations."
  },
  {
    "objectID": "big_picture.html#rubric-on-this-page",
    "href": "big_picture.html#rubric-on-this-page",
    "title": "Big Picture",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nTitle\n\nYour big picture page should have a creative/click-bait-y title/headline that provides a hint about your thesis.\n\nClarity of Explanation\n\nYou should have a clear thesis/goal for this page. What are you trying to show? Make sure that you explain your analysis in detail but don’t go into top much mathematics or statistics. The audience for this page is the general public (to the extent possible). Your thesis should be a statement, not a question.\nEach figure should be very polished and also not too complicated. There should be a clear interpretation of the figure so the figure has a clear purpose. Even something like a histogram can be difficult to interpret for non-experts.\n\nCreativity\n\nDo your best to make things interesting. Think of a story. Think of how each part of your analysis supports the previous part or provides a different perspective.\n\nInteractive component\n\nQuality and ease of use of the interactive components. Is it clear what can be explored using your interactive components? Does it enhance and reinforce your conclusions?\n\nThis page should be self-contained.\n\nNote: This page should have no code visible, i.e. use #| echo: FALSE."
  },
  {
    "objectID": "big_picture.html#rubric-other-components",
    "href": "big_picture.html#rubric-other-components",
    "title": "Big Picture",
    "section": "Rubric: Other components",
    "text": "Rubric: Other components\n\nVideo Recording\nMake a video recording (probably using Zoom) demonstrating your interactive components. You should provide a quick explanation of your data and demonstrate some of the conclusions from your EDA. This video should be no longer than 4 minutes. Include a link to your video (and password if needed) in your README.md file on your Github repository. You are not required to provide a link on the website. This can be presented by any subset of the team members.\n\n\nRest of the Site\nFinally, here are important things to keep in mind for the rest of the site.\nThe main title of your page is informative. Each post has an author/description/informative title. All lab required posts are present. Each page (including the home page) has a nice featured image associated with it. Your about page is up to date and clean. You have removed the generic posts from the initial site template."
  }
]